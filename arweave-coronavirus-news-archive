## Proposal name:
arweave-coronavirus-news-archive

## Summary:
I would like to create a news archive using keywords that will provide a large percentage of relevant news content available relating to the Worldwide Coronavirus (covid-19) pandemic. The data will be stored on the arweave network in json format.

## Motivation:
I want to do this to create the largest coronavirus news archive in the world. Arweave could gain by increased use of the network and this data would be available to all developers to create front end interfaces. I myself will work on a front end once I have completed the back end. On the front end I hope to allow users to load their wallet, search for news articles, and archive them to the arweave network. This data can also be used to automate archival of news articles to arweave.

## Specification:
I will fork this repo and add additional functionality in order to be able to capture all data available. https://github.com/crypto-guys/arweaveNewsPermafeed
I will add a source tag, author tag, title tag, description tag, link tag, and image link tag as well as add the ability to get all pages of results. I am not sure if all of these tags will be required but I will add whatever is needed.

I will also run the script on one of my vps servers as long as there is funding to do so. Depending on the amount of funding available I could start archiving the data starting from the beginning of December 2019 or start from any date that is reasonable.

## Team and previous work:
This is my previous work.

https://github.com/crypto-guys/

https://github.com/pinkgoatcheese/

## Timeline:
These are estimations because I work at varying speeds. 

- 8 hours research
- 10 hours backend
- 40 hours frontend
- vps cost 7 DAI per month

I might be able to do this much faster than what I estimate however maybe not.

Total: 10 + 40 + 8 (58) hours

Storage Costs = With the keyword coronavirus i can currently get data starting from 03-06-2020 which results in about 900,000 articles. I can receive 100 results per page. One page of results is approximatly 91382 bytes. I estimage that to be 9000 transactions x 91382 bytes. That is 822438000 bytes for the keyword coronavirus. The cost to store that data could be about 1.7AR

I would like to also archive the keyword covid-19 i can currently get data starting from 03-06-2020 which results in 660,000 articles. 100 results per page is 6,600 transactions at 91382 bytes = 603121200 bytes. The cost for this data could be AR = 1.24AR

The total storage cost to store 1 month of data would likely be less than 4AR.

## Grant requested (DAI):
1050 DAI
I will fund the archive bot with my own AR in the amount of 12AR if approved. This will allow it to archive approximatly 3 months of news.

## Ethereum Address:
0x3D6087EbC73fb4f6d961a42076fA43A0Ae4e425c
